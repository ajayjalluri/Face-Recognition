{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWN_FACES_DIR = 'known_faces'\n",
    "UNKNOWN_FACES_DIR = 'unknown_faces'\n",
    "TOLERANCE = 0.6\n",
    "FRAME_THICKNESS = 3\n",
    "FONT_THICKNESS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading known faces...\n"
     ]
    }
   ],
   "source": [
    "print('Loading known faces...')\n",
    "known_faces = []\n",
    "known_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in os.listdir(KNOWN_FACES_DIR):\n",
    "\n",
    "    # Next we load every file of faces of known person\n",
    "    for filename in os.listdir(f'{KNOWN_FACES_DIR}/{name}'):\n",
    "\n",
    "        # Load an image\n",
    "        image = face_recognition.load_image_file(f'{KNOWN_FACES_DIR}/{name}/{filename}')\n",
    "        \n",
    "        # Get 128-dimension face encoding\n",
    "        # Always returns a list of found faces, for this purpose we take first face only (assuming one face per image as you can't be twice on one image)\n",
    "        encoding = face_recognition.face_encodings(image)\n",
    "        if len(encoding) > 0:\n",
    "             biden_encoding = encoding[0]\n",
    "             known_faces.append(np.array(biden_encoding).reshape(128))\n",
    "             known_names.append(name)\n",
    "        else:\n",
    "            pass \n",
    "            \n",
    "        \n",
    "\n",
    "        # Append encodings and name\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(known_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ajay', 'ajay', 'ajay', 'tavva', 'tavva']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.96856856e-01  3.65737937e-02  7.90140480e-02 -9.71663976e-04\n",
      " -4.45016846e-02 -1.00752905e-01 -4.03938219e-02 -1.67211443e-02\n",
      "  1.00207657e-01 -9.63001773e-02  1.85404509e-01 -4.55710813e-02\n",
      " -1.69742599e-01 -1.27954319e-01  1.14233634e-02  8.29739794e-02\n",
      " -1.65133014e-01 -1.26924366e-01 -3.18874381e-02 -1.16482250e-01\n",
      "  2.97396518e-02 -7.62604177e-04  1.52792344e-02  6.18601218e-02\n",
      " -1.45620123e-01 -3.81449163e-01 -7.37554058e-02 -1.70712858e-01\n",
      "  1.67583562e-02 -7.61220679e-02 -1.86123550e-02  4.80487794e-02\n",
      " -1.64117187e-01 -2.01446936e-02 -3.10911592e-02  4.96202819e-02\n",
      "  3.01213060e-02 -1.91799216e-02  1.53848365e-01 -2.01187376e-03\n",
      " -5.37068248e-02 -1.54034168e-01  5.87601848e-02  2.94011414e-01\n",
      "  1.46608874e-01  7.21874982e-02  2.20864397e-02  4.17589806e-02\n",
      "  6.28009140e-02 -2.22463921e-01  6.87583536e-03  1.37114838e-01\n",
      "  7.37359375e-02  3.10099926e-02  1.12748712e-01 -7.95104951e-02\n",
      "  3.17516178e-02 -5.17255068e-02 -1.70513093e-01  4.05281857e-02\n",
      " -2.16966420e-02  1.13902614e-02 -9.38989297e-02 -2.51790769e-02\n",
      "  3.14393014e-01  1.07549787e-01 -9.97342914e-02 -7.90261179e-02\n",
      "  1.11941710e-01 -2.03886896e-01 -4.27327156e-02  1.26840286e-02\n",
      " -1.04344890e-01 -1.32286415e-01 -2.41234586e-01  6.41657971e-03\n",
      "  3.54229629e-01  1.48928747e-01 -1.42506868e-01  6.83389977e-02\n",
      " -1.24742702e-01 -9.55068022e-02  8.95533562e-02  2.44526081e-02\n",
      " -1.28400519e-01  9.26687643e-02 -1.09314896e-01  8.41912553e-02\n",
      "  1.55615836e-01 -8.01576488e-03 -3.13604362e-02  1.38715521e-01\n",
      "  5.59184700e-05  9.47631616e-03  4.21986133e-02 -6.27395958e-02\n",
      " -8.13434348e-02 -1.77234486e-02 -1.03201479e-01 -2.57401150e-02\n",
      "  1.20690338e-01 -2.92209797e-02  7.54119270e-03  5.32848239e-02\n",
      " -1.32836550e-01  4.36178893e-02  2.42641829e-02 -5.23121580e-02\n",
      " -2.55642012e-02  5.60653582e-02 -2.32017562e-01 -1.03412092e-01\n",
      "  9.36599821e-02 -1.87771782e-01  1.08385459e-01  1.43401980e-01\n",
      "  1.20531693e-02  1.43005297e-01  6.79873079e-02  3.64520028e-02\n",
      " -2.63560954e-02  8.93444009e-03 -4.46128361e-02 -5.47491349e-02\n",
      "  5.37326150e-02  5.29589318e-03  6.25592917e-02 -9.65122320e-03]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(known_faces[0]).reshape(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing unknown faces...\n",
      "Filename IMG_20200407_174629_063.jpg(128,)\n",
      ", found 1 face(s)\n",
      " - tavva from [False, False, False, True, True]\n",
      "Filename WhatsApp Image 2020-04-11 at 10.08.33 AM (1).jpeg(128,)\n",
      ", found 1 face(s)\n",
      "Filename WhatsApp Image 2020-04-11 at 10.08.33 AM.jpeg(128,)\n",
      ", found 1 face(s)\n",
      " - ajay from [True, False, True, False, False]\n"
     ]
    }
   ],
   "source": [
    "print('Processing unknown faces...')\n",
    "# Now let's loop over a folder of faces we want to label\n",
    "for filename in os.listdir(UNKNOWN_FACES_DIR):\n",
    "\n",
    "    # Load image\n",
    "    print(f'Filename {filename}', end='')\n",
    "    image = face_recognition.load_image_file(f'{UNKNOWN_FACES_DIR}/{filename}')\n",
    "\n",
    "    # This time we first grab face locations - we'll need them to draw boxes\n",
    "    locations = face_recognition.face_locations(image, model=\"cnn\")\n",
    "\n",
    "    # Now since we know loctions, we can pass them to face_encodings as second argument\n",
    "    # Without that it will search for faces once again slowing down whole process\n",
    "    encodings = face_recognition.face_encodings(image, locations)\n",
    "    print(encodings[0].shape)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # But this time we assume that there might be more faces in an image - we can find faces of dirrerent people\n",
    "    print(f', found {len(encodings)} face(s)')\n",
    "    for face_encoding, face_location in zip(encodings, locations):\n",
    "\n",
    "        # We use compare_faces (but might use face_distance as well)\n",
    "        # Returns array of True/False values in order of passed known_faces\n",
    "        results = face_recognition.compare_faces(known_faces, face_encoding,0.4)\n",
    "\n",
    "        # Since order is being preserved, we check if any face was found then grab index\n",
    "        # then label (name) of first matching known face withing a tolerance\n",
    "        match = None\n",
    "        if True in results:  # If at least one is true, get a name of first of found labels\n",
    "            match = known_names[results.index(True)]\n",
    "            print(f' - {match} from {results}')\n",
    "\n",
    "            # Each location contains positions in order: top, right, bottom, left\n",
    "            top_left = (face_location[3], face_location[0])\n",
    "            bottom_right = (face_location[1], face_location[2])\n",
    "\n",
    "            # Get color by name using our fancy function\n",
    "            color = [0,255,0]\n",
    "\n",
    "            # Paint frame\n",
    "            cv2.rectangle(image, top_left, bottom_right, color, FRAME_THICKNESS)\n",
    "\n",
    "            # Now we need smaller, filled grame below for a name\n",
    "            # This time we use bottom in both corners - to start from bottom and move 50 pixels down\n",
    "            top_left = (face_location[3], face_location[2])\n",
    "            bottom_right = (face_location[1], face_location[2] + 22)\n",
    "\n",
    "            # Paint frame\n",
    "            cv2.rectangle(image, top_left, bottom_right, color, cv2.FILLED)\n",
    "\n",
    "            # Wite a name\n",
    "            cv2.putText(image, match, (face_location[3] + 10, face_location[2] + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0,0), FONT_THICKNESS)\n",
    "\n",
    "            # Show image\n",
    "cv2.imshow(filename, image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
